{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from typing import List\nimport pandas as pd\nimport scipy as sp\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nrandom_state = 20\n\nresponse = 'sales'\n\ncategorical = [\n    'productID',\n    'brandID',\n    'weekday',\n    'attribute1',\n]\n\nnumerical = [\n    'attribute2',\n    'clickVolume',\n    'avgOriginalUnitPrice',\n    'avgFinalUnitPrice',\n    'ma14SalesVolume',\n    'meanAge',\n    'gender',\n    'meanEducation',\n    'maritalStatus',\n    'plus',\n    'meanPurchasePower',\n    'meanUserLevel',\n    'meanCityLevel',\n    # 'sales',\n]\n\nclass Preprocessor:\n    def __init__(self, encode_categorical, scale_numeric):\n        self.encode_categorical = encode_categorical\n        self.scale_numeric = scale_numeric\n        self.encoder = OneHotEncoder(drop='first', sparse=False)\n        self.sscaler = StandardScaler(with_mean=False, with_std=True)\n    \n    def fit(\n        self, \n        data: pd.DataFrame, \n        categorical: List[str] = categorical, \n        numerical: List[str] = numerical,\n    ):\n        self.encoder.fit(data[categorical].apply(lambda x: x.astype('int')))\n        self.sscaler.fit(data[numerical])\n        return self\n    \n    def transform(\n        self,\n        data: pd.DataFrame, \n        categorical: List[str] = categorical, \n        numerical: List[str] = numerical,\n    ):\n        # To be safe\n        data = data.copy()\n        \n        # Cast data types\n        data[categorical] = data[categorical].apply(lambda x: x.astype('category'))\n        data[numerical] = data[numerical].apply(lambda x: x.astype('float'))\n\n        # Append dummies as new columns\n        if self.encode_categorical:\n            # data = pd.get_dummies(data, drop_first=False)\n            encoded = self.encoder.transform(data[categorical])\n            columns = self.encoder.get_feature_names(categorical)\n            data = data.drop(columns=categorical)\n            data[columns] = encoded\n            # data = pd.concat([\n            #     data.drop(columns=categorical),\n            #     pd.DataFrame(encoded, columns=columns)\n            # ], axis=1)\n        \n        # handle numerical data\n        if self.scale_numeric:\n            data[numerical] = self.sscaler.transform(data[numerical])\n\n        return data\n        \ndef load_datasets(train_file, test_file):\n    \"\"\"Utility function to load and preprocess standardized data\"\"\"\n    # Split train-val-test split\n    train_val = pd.read_csv(train_file, index_col=0)\n    test = pd.read_csv(test_file, index_col=0)\n    train, validation = train_test_split(train_val, test_size=0.2, random_state=random_state)\n    \n    # Fit preprocessor to train data only\n    preprocessor = Preprocessor(encode_categorical=True, scale_numeric=True)\n    preprocessor.fit(train)\n    \n    # Ensure all datasets undergo the same preprocessing steps\n    train = preprocessor.transform(train)\n    validation = preprocessor.transform(validation)\n    test = preprocessor.transform(test)\n    \n    return train, validation, test\n\n# Check that preprocessing steps are reproducible\nfoo, *_ = load_datasets(\n    train_file = '../input/datatrain/Data-train.csv', \n    test_file = '../input/datatest/Data-test.csv', \n)\n\nbar, *_ = load_datasets(\n    train_file = '../input/datatrain/Data-train.csv', \n    test_file = '../input/datatest/Data-test.csv', \n)\n\nassert all(foo == bar), 'Preprocessing not reproducible!'\n\n# Module exports\ntrain, validation, test = load_datasets(\n    train_file = '../input/datatrain/Data-train.csv', \n    test_file = '../input/datatest/Data-test.csv', \n)\n\ny = response\nX = train.columns.drop(response)\n\n#Further dividing the train dataset in 80-20 split, so we dont touch validation till the end\n# def data_process():\n#Seperating response and parameters\nDTy = train.sales\nDTX = train.drop(['sales'], axis=1)\n\n#Splitting data in training and test dataset\nDTX_train,DTX_test,DTy_train,DTy_test = train_test_split(DTX,DTy, test_size=0.2,random_state=random_state)\n\n# return DTX_train,DTX_test,DTy_train,DTy_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Regressor using grid search\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error as mse\n\nRF = RandomForestRegressor()\nRF.fit(DTX_train,DTy_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Grid Search\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {'n_estimators' : (10,30,50,70,90,100)\n              , 'criterion' : ('mse','mae')\n              , 'max_depth' : (3,5,7,9,10)\n              , 'max_features' : (None,'auto','sqrt')\n              , 'min_samples_split' : (2,4,6)\n              , 'ccp_alpha' : (0.01,0.02,0.03,0.04)\n             }\n\nRF_grid = GridSearchCV(RandomForestRegressor(), scoring = 'neg_mean_squared_error',param_grid = parameters,cv = 5)\n\nRF_grid_model = RF_grid.fit(DTX_train,DTy_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_grid_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_grid_model.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF = RandomForestRegressor(max_depth=10, min_samples_split=4, n_estimators=50)\n# RF = RandomForestRegressor(max_depth=7, min_samples_split=4, n_estimators=50,n_jobs=-1)\nRF.fit(DTX_train,DTy_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation time\n\ny_pred = RF.predict(DTX_test)\nprint(f'Test : {mse(y_pred,DTy_test):.3f}')\n# print(f'Train : {mse(y_pred,DTy_train):.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}