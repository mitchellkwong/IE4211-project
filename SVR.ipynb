{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd02e7bd34cf8adaff6fe39da52b2b333248e2f4a424e35a69aad602b99d1bfe04e",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import train and create training and test datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import train\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from multiprocessing import cpu_count\n",
    "from utils import StandardizedGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop('sales', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train.sales"
   ]
  },
  {
   "source": [
    "# SVR(Radial)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "nda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVR(max_iter=10000), n_jobs=1,\n",
       "             param_grid={'C': [1250, 1300, 1350], 'epsilon': [2.5, 3, 3.5],\n",
       "                         'gamma': [0.025, 0.05, 0.075]},\n",
       "             refit='neg_mean_squared_error', return_train_score=True,\n",
       "             scoring=['neg_mean_squared_error', 'r2'], verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "modelr = SVR(kernel=\"rbf\",max_iter= 10000)\n",
    "\n",
    "gamma = [0.025,0.05,0.075]\n",
    "C =  [1250,1300,1350]\n",
    "epsilon = [2.5,3,3.5]\n",
    "paramr = {'C' :C, 'gamma': gamma, 'epsilon' : epsilon}\n",
    "\n",
    "gsradial1 = StandardizedGridSearchCV(modelr,paramr, n_jobs=1,verbose = False)\n",
    "\n",
    "gsradial1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C     epsilon  gamma\n",
       "1300  3.0      0.050   -1891.883093\n",
       "      3.5      0.050   -1892.929385\n",
       "1350  2.5      0.050   -1893.822556\n",
       "      3.0      0.050   -1893.855326\n",
       "      3.5      0.050   -1894.668210\n",
       "1300  2.5      0.050   -1895.314375\n",
       "1250  3.0      0.050   -1897.279922\n",
       "      3.5      0.050   -1897.359645\n",
       "      2.5      0.050   -1899.174450\n",
       "               0.075   -1930.460308\n",
       "      3.0      0.075   -1932.297440\n",
       "1300  2.5      0.075   -1934.536658\n",
       "1250  3.5      0.075   -1934.771270\n",
       "1350  2.5      0.075   -1935.592213\n",
       "1300  3.0      0.075   -1936.739935\n",
       "1350  3.0      0.075   -1937.351859\n",
       "1300  3.5      0.075   -1939.057965\n",
       "1350  3.5      0.075   -1939.497068\n",
       "               0.025   -2039.780016\n",
       "      3.0      0.025   -2042.695191\n",
       "      2.5      0.025   -2045.279634\n",
       "1300  3.5      0.025   -2046.362463\n",
       "      3.0      0.025   -2049.297451\n",
       "      2.5      0.025   -2050.700769\n",
       "1250  3.5      0.025   -2052.738216\n",
       "      3.0      0.025   -2055.345129\n",
       "      2.5      0.025   -2057.334946\n",
       "Name: mean_test_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "gsradial1.results['mean_test_neg_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C     epsilon  gamma\n",
       "1300  3.0      0.050    -829.147463\n",
       "      3.5      0.050    -829.440600\n",
       "1350  2.5      0.050    -813.606430\n",
       "      3.0      0.050    -813.631832\n",
       "      3.5      0.050    -814.081382\n",
       "1300  2.5      0.050    -828.871377\n",
       "1250  3.0      0.050    -845.682179\n",
       "      3.5      0.050    -845.967402\n",
       "      2.5      0.050    -845.135557\n",
       "               0.075    -547.205155\n",
       "      3.0      0.075    -547.247574\n",
       "1300  2.5      0.075    -531.063112\n",
       "1250  3.5      0.075    -547.689601\n",
       "1350  2.5      0.075    -516.654310\n",
       "1300  3.0      0.075    -531.204264\n",
       "1350  3.0      0.075    -516.786100\n",
       "1300  3.5      0.075    -531.608323\n",
       "1350  3.5      0.075    -517.396788\n",
       "               0.025   -1394.775516\n",
       "      3.0      0.025   -1397.886587\n",
       "      2.5      0.025   -1400.909479\n",
       "1300  3.5      0.025   -1411.445586\n",
       "      3.0      0.025   -1413.558232\n",
       "      2.5      0.025   -1417.505727\n",
       "1250  3.5      0.025   -1428.167140\n",
       "      3.0      0.025   -1430.384019\n",
       "      2.5      0.025   -1433.522535\n",
       "Name: mean_train_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "gsradial1.results['mean_train_neg_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "C    epsilon gamma                                                 \n",
       "1300 3.0     0.050       0.829903      0.065854         0.051771   \n",
       "     3.5     0.050       0.775498      0.072712         0.045983   \n",
       "1350 2.5     0.050       0.801991      0.111988         0.044781   \n",
       "     3.0     0.050       0.789651      0.074729         0.053531   \n",
       "     3.5     0.050       0.708292      0.070458         0.043272   \n",
       "1300 2.5     0.050       0.784792      0.058641         0.047649   \n",
       "1250 3.0     0.050       0.772920      0.073513         0.059451   \n",
       "     3.5     0.050       0.747952      0.108606         0.050576   \n",
       "     2.5     0.050       0.836529      0.125782         0.051178   \n",
       "             0.075       0.768437      0.071870         0.057682   \n",
       "     3.0     0.075       0.743784      0.140810         0.045379   \n",
       "1300 2.5     0.075       0.834043      0.062294         0.069565   \n",
       "1250 3.5     0.075       0.779161      0.087002         0.050286   \n",
       "1350 2.5     0.075       0.681579      0.059522         0.045985   \n",
       "1300 3.0     0.075       0.803412      0.088220         0.058484   \n",
       "1350 3.0     0.075       0.766438      0.094365         0.050069   \n",
       "1300 3.5     0.075       0.789260      0.084868         0.048982   \n",
       "1350 3.5     0.075       0.639023      0.039574         0.041279   \n",
       "             0.025       0.697495      0.108844         0.044879   \n",
       "     3.0     0.025       0.791283      0.062725         0.044076   \n",
       "     2.5     0.025       0.898503      0.102372         0.058574   \n",
       "1300 3.5     0.025       0.776980      0.054748         0.041300   \n",
       "     3.0     0.025       0.804169      0.086424         0.055181   \n",
       "     2.5     0.025       0.669215      0.035570         0.039477   \n",
       "1250 3.5     0.025       0.671217      0.044765         0.044515   \n",
       "     3.0     0.025       0.692767      0.056127         0.048517   \n",
       "     2.5     0.025       0.735128      0.038044         0.040202   \n",
       "\n",
       "                    std_score_time  split0_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                                       \n",
       "1300 3.0     0.050        0.017056                        -1145.356536   \n",
       "     3.5     0.050        0.012798                        -1144.199280   \n",
       "1350 2.5     0.050        0.004944                        -1151.214365   \n",
       "     3.0     0.050        0.020557                        -1151.771193   \n",
       "     3.5     0.050        0.009351                        -1150.417402   \n",
       "1300 2.5     0.050        0.011683                        -1148.628297   \n",
       "1250 3.0     0.050        0.020627                        -1137.752021   \n",
       "     3.5     0.050        0.013313                        -1139.756403   \n",
       "     2.5     0.050        0.013872                        -1133.115910   \n",
       "             0.075        0.017425                        -1260.234665   \n",
       "     3.0     0.075        0.008711                        -1263.921834   \n",
       "1300 2.5     0.075        0.022368                        -1278.004064   \n",
       "1250 3.5     0.075        0.015259                        -1268.771092   \n",
       "1350 2.5     0.075        0.007430                        -1295.680843   \n",
       "1300 3.0     0.075        0.022010                        -1281.983027   \n",
       "1350 3.0     0.075        0.012830                        -1300.596133   \n",
       "1300 3.5     0.075        0.011335                        -1285.538748   \n",
       "1350 3.5     0.075        0.008092                        -1302.373110   \n",
       "             0.025        0.012536                        -1084.677640   \n",
       "     3.0     0.025        0.008369                        -1081.785910   \n",
       "     2.5     0.025        0.022573                        -1083.066569   \n",
       "1300 3.5     0.025        0.004949                        -1083.053677   \n",
       "     3.0     0.025        0.017542                        -1088.766989   \n",
       "     2.5     0.025        0.002148                        -1089.490943   \n",
       "1250 3.5     0.025        0.010016                        -1083.375338   \n",
       "     3.0     0.025        0.018406                        -1085.041436   \n",
       "     2.5     0.025        0.003176                        -1085.846536   \n",
       "\n",
       "                    split1_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "1300 3.0     0.050                        -1049.564833   \n",
       "     3.5     0.050                        -1047.412773   \n",
       "1350 2.5     0.050                        -1056.226769   \n",
       "     3.0     0.050                        -1051.400180   \n",
       "     3.5     0.050                        -1052.949864   \n",
       "1300 2.5     0.050                        -1053.856836   \n",
       "1250 3.0     0.050                        -1046.046100   \n",
       "     3.5     0.050                        -1046.769176   \n",
       "     2.5     0.050                        -1049.344059   \n",
       "             0.075                        -1139.704693   \n",
       "     3.0     0.075                        -1135.041694   \n",
       "1300 2.5     0.075                        -1133.337494   \n",
       "1250 3.5     0.075                        -1131.536855   \n",
       "1350 2.5     0.075                        -1125.755755   \n",
       "1300 3.0     0.075                        -1127.781546   \n",
       "1350 3.0     0.075                        -1121.855807   \n",
       "1300 3.5     0.075                        -1124.025170   \n",
       "1350 3.5     0.075                        -1119.038598   \n",
       "             0.025                         -872.031071   \n",
       "     3.0     0.025                         -875.964407   \n",
       "     2.5     0.025                         -874.134170   \n",
       "1300 3.5     0.025                         -870.366957   \n",
       "     3.0     0.025                         -874.993231   \n",
       "     2.5     0.025                         -872.199547   \n",
       "1250 3.5     0.025                         -869.388026   \n",
       "     3.0     0.025                         -870.200134   \n",
       "     2.5     0.025                         -879.561743   \n",
       "\n",
       "                    split2_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "1300 3.0     0.050                         -804.734634   \n",
       "     3.5     0.050                         -804.461785   \n",
       "1350 2.5     0.050                         -819.434599   \n",
       "     3.0     0.050                         -818.318093   \n",
       "     3.5     0.050                         -819.503605   \n",
       "1300 2.5     0.050                         -807.502433   \n",
       "1250 3.0     0.050                         -791.236216   \n",
       "     3.5     0.050                         -790.159228   \n",
       "     2.5     0.050                         -795.583227   \n",
       "             0.075                        -1144.569273   \n",
       "     3.0     0.075                        -1150.157344   \n",
       "1300 2.5     0.075                        -1192.452726   \n",
       "1250 3.5     0.075                        -1158.782086   \n",
       "1350 2.5     0.075                        -1202.785831   \n",
       "1300 3.0     0.075                        -1201.327942   \n",
       "1350 3.0     0.075                        -1207.355622   \n",
       "1300 3.5     0.075                        -1209.554048   \n",
       "1350 3.5     0.075                        -1212.786558   \n",
       "             0.025                         -706.124831   \n",
       "     3.0     0.025                         -703.307260   \n",
       "     2.5     0.025                         -703.073201   \n",
       "1300 3.5     0.025                         -703.389330   \n",
       "     3.0     0.025                         -703.577293   \n",
       "     2.5     0.025                         -703.674034   \n",
       "1250 3.5     0.025                         -701.572350   \n",
       "     3.0     0.025                         -702.686740   \n",
       "     2.5     0.025                         -706.075019   \n",
       "\n",
       "                    split3_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "1300 3.0     0.050                        -1696.723513   \n",
       "     3.5     0.050                        -1697.011940   \n",
       "1350 2.5     0.050                        -1716.517109   \n",
       "     3.0     0.050                        -1720.390317   \n",
       "     3.5     0.050                        -1717.757520   \n",
       "1300 2.5     0.050                        -1702.327707   \n",
       "1250 3.0     0.050                        -1678.450064   \n",
       "     3.5     0.050                        -1676.512710   \n",
       "     2.5     0.050                        -1680.255812   \n",
       "             0.075                        -1688.277930   \n",
       "     3.0     0.075                        -1683.932803   \n",
       "1300 2.5     0.075                        -1693.225206   \n",
       "1250 3.5     0.075                        -1680.932076   \n",
       "1350 2.5     0.075                        -1700.041110   \n",
       "1300 3.0     0.075                        -1690.355162   \n",
       "1350 3.0     0.075                        -1697.712410   \n",
       "1300 3.5     0.075                        -1688.070185   \n",
       "1350 3.5     0.075                        -1694.246215   \n",
       "             0.025                        -1572.458518   \n",
       "     3.0     0.025                        -1578.353972   \n",
       "     2.5     0.025                        -1577.021024   \n",
       "1300 3.5     0.025                        -1569.970893   \n",
       "     3.0     0.025                        -1569.759123   \n",
       "     2.5     0.025                        -1575.756535   \n",
       "1250 3.5     0.025                        -1565.311624   \n",
       "     3.0     0.025                        -1572.494166   \n",
       "     2.5     0.025                        -1568.076677   \n",
       "\n",
       "                    split4_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "1300 3.0     0.050                         -721.535961   \n",
       "     3.5     0.050                         -723.558499   \n",
       "1350 2.5     0.050                         -726.533684   \n",
       "     3.0     0.050                         -726.648454   \n",
       "     3.5     0.050                         -728.269199   \n",
       "1300 2.5     0.050                         -719.991005   \n",
       "1250 3.0     0.050                         -716.896878   \n",
       "     3.5     0.050                         -717.759729   \n",
       "     2.5     0.050                         -713.863298   \n",
       "             0.075                         -744.979050   \n",
       "     3.0     0.075                         -746.487257   \n",
       "1300 2.5     0.075                         -745.092593   \n",
       "1250 3.5     0.075                         -747.962572   \n",
       "1350 2.5     0.075                         -747.068750   \n",
       "1300 3.0     0.075                         -747.441252   \n",
       "1350 3.0     0.075                         -748.546346   \n",
       "1300 3.5     0.075                         -749.073198   \n",
       "1350 3.5     0.075                         -750.943737   \n",
       "             0.025                         -873.568759   \n",
       "     3.0     0.025                         -871.784271   \n",
       "     2.5     0.025                         -868.051209   \n",
       "1300 3.5     0.025                         -875.552211   \n",
       "     3.0     0.025                         -876.359757   \n",
       "     2.5     0.025                         -872.225229   \n",
       "1250 3.5     0.025                         -880.941750   \n",
       "     3.0     0.025                         -874.981488   \n",
       "     2.5     0.025                         -874.892014   \n",
       "\n",
       "                    split5_test_neg_mean_squared_error  ...  split2_train_r2  \\\n",
       "C    epsilon gamma                                      ...                    \n",
       "1300 3.0     0.050                         -873.827602  ...         0.916324   \n",
       "     3.5     0.050                         -875.512598  ...         0.916312   \n",
       "1350 2.5     0.050                         -874.368429  ...         0.918043   \n",
       "     3.0     0.050                         -877.946861  ...         0.918182   \n",
       "     3.5     0.050                         -873.917502  ...         0.918198   \n",
       "1300 2.5     0.050                         -874.059731  ...         0.916293   \n",
       "1250 3.0     0.050                         -874.242000  ...         0.914477   \n",
       "     3.5     0.050                         -874.700392  ...         0.914520   \n",
       "     2.5     0.050                         -871.837862  ...         0.914523   \n",
       "             0.075                         -892.220052  ...         0.948569   \n",
       "     3.0     0.075                         -894.094790  ...         0.948568   \n",
       "1300 2.5     0.075                         -893.970204  ...         0.950243   \n",
       "1250 3.5     0.075                         -896.455363  ...         0.948528   \n",
       "1350 2.5     0.075                         -896.668196  ...         0.951287   \n",
       "1300 3.0     0.075                         -896.559808  ...         0.950231   \n",
       "1350 3.0     0.075                         -897.992262  ...         0.951218   \n",
       "1300 3.5     0.075                         -897.983430  ...         0.950180   \n",
       "1350 3.5     0.075                         -899.578797  ...         0.951107   \n",
       "             0.025                         -854.657564  ...         0.856845   \n",
       "     3.0     0.025                         -852.966550  ...         0.856380   \n",
       "     2.5     0.025                         -852.674201  ...         0.855969   \n",
       "1300 3.5     0.025                         -850.274942  ...         0.855124   \n",
       "     3.0     0.025                         -849.926472  ...         0.855097   \n",
       "     2.5     0.025                         -850.315923  ...         0.854661   \n",
       "1250 3.5     0.025                         -851.748339  ...         0.853684   \n",
       "     3.0     0.025                         -847.745252  ...         0.853291   \n",
       "     2.5     0.025                         -848.179742  ...         0.853081   \n",
       "\n",
       "                    split3_train_r2  split4_train_r2  split5_train_r2  \\\n",
       "C    epsilon gamma                                                      \n",
       "1300 3.0     0.050         0.917709         0.912960         0.917079   \n",
       "     3.5     0.050         0.917602         0.912928         0.917002   \n",
       "1350 2.5     0.050         0.919141         0.914532         0.918621   \n",
       "     3.0     0.050         0.918998         0.914469         0.918408   \n",
       "     3.5     0.050         0.918994         0.914272         0.918353   \n",
       "1300 2.5     0.050         0.917710         0.913211         0.917179   \n",
       "1250 3.0     0.050         0.916135         0.911377         0.915588   \n",
       "     3.5     0.050         0.916111         0.911323         0.915468   \n",
       "     2.5     0.050         0.916196         0.911599         0.915554   \n",
       "             0.075         0.945046         0.941287         0.942875   \n",
       "     3.0     0.075         0.945084         0.941243         0.942941   \n",
       "1300 2.5     0.075         0.946591         0.942969         0.944410   \n",
       "1250 3.5     0.075         0.945068         0.941189         0.942974   \n",
       "1350 2.5     0.075         0.948079         0.944515         0.945841   \n",
       "1300 3.0     0.075         0.946624         0.942956         0.944473   \n",
       "1350 3.0     0.075         0.948072         0.944552         0.945910   \n",
       "1300 3.5     0.075         0.946621         0.942907         0.944510   \n",
       "1350 3.5     0.075         0.947966         0.944511         0.945933   \n",
       "             0.025         0.861305         0.856520         0.861791   \n",
       "     3.0     0.025         0.861148         0.856138         0.861345   \n",
       "     2.5     0.025         0.860961         0.856049         0.860974   \n",
       "1300 3.5     0.025         0.859518         0.854898         0.859903   \n",
       "     3.0     0.025         0.859316         0.854479         0.859772   \n",
       "     2.5     0.025         0.859218         0.854307         0.859208   \n",
       "1250 3.5     0.025         0.857529         0.853472         0.858559   \n",
       "     3.0     0.025         0.857425         0.853104         0.858132   \n",
       "     2.5     0.025         0.857320         0.852658         0.857796   \n",
       "\n",
       "                    split6_train_r2  split7_train_r2  split8_train_r2  \\\n",
       "C    epsilon gamma                                                      \n",
       "1300 3.0     0.050         0.911893         0.912837         0.971102   \n",
       "     3.5     0.050         0.911828         0.912817         0.971109   \n",
       "1350 2.5     0.050         0.913385         0.914385         0.972150   \n",
       "     3.0     0.050         0.913316         0.914350         0.972246   \n",
       "     3.5     0.050         0.913196         0.914324         0.972213   \n",
       "1300 2.5     0.050         0.912092         0.912875         0.971000   \n",
       "1250 3.0     0.050         0.910524         0.911278         0.969841   \n",
       "     3.5     0.050         0.910397         0.911224         0.969928   \n",
       "     2.5     0.050         0.910649         0.911326         0.969818   \n",
       "             0.075         0.936932         0.940794         0.988044   \n",
       "     3.0     0.075         0.936843         0.940819         0.987888   \n",
       "1300 2.5     0.075         0.938525         0.942356         0.988745   \n",
       "1250 3.5     0.075         0.936736         0.940785         0.987695   \n",
       "1350 2.5     0.075         0.940055         0.943794         0.989421   \n",
       "1300 3.0     0.075         0.938453         0.942333         0.988593   \n",
       "1350 3.0     0.075         0.939966         0.943807         0.989241   \n",
       "1300 3.5     0.075         0.938349         0.942311         0.988400   \n",
       "1350 3.5     0.075         0.939882         0.943779         0.989038   \n",
       "             0.025         0.855725         0.855411         0.932837   \n",
       "     3.0     0.025         0.855848         0.855381         0.932623   \n",
       "     2.5     0.025         0.855603         0.854582         0.932438   \n",
       "1300 3.5     0.025         0.854526         0.853423         0.931659   \n",
       "     3.0     0.025         0.854306         0.853228         0.931448   \n",
       "     2.5     0.025         0.853783         0.852754         0.931367   \n",
       "1250 3.5     0.025         0.852756         0.851642         0.930503   \n",
       "     3.0     0.025         0.852648         0.851405         0.930238   \n",
       "     2.5     0.025         0.852260         0.851227         0.930085   \n",
       "\n",
       "                    split9_train_r2  mean_train_r2  std_train_r2  \n",
       "C    epsilon gamma                                                \n",
       "1300 3.0     0.050         0.912319       0.919711      0.017319  \n",
       "     3.5     0.050         0.912334       0.919683      0.017325  \n",
       "1350 2.5     0.050         0.913824       0.921222      0.017163  \n",
       "     3.0     0.050         0.913891       0.921221      0.017186  \n",
       "     3.5     0.050         0.913845       0.921177      0.017187  \n",
       "1300 2.5     0.050         0.912235       0.919737      0.017284  \n",
       "1250 3.0     0.050         0.910692       0.918102      0.017451  \n",
       "     3.5     0.050         0.910744       0.918075      0.017485  \n",
       "     2.5     0.050         0.910670       0.918155      0.017425  \n",
       "             0.075         0.942703       0.947085      0.013941  \n",
       "     3.0     0.075         0.942770       0.947078      0.013897  \n",
       "1300 2.5     0.075         0.944606       0.948650      0.013661  \n",
       "1250 3.5     0.075         0.942770       0.947031      0.013852  \n",
       "1350 2.5     0.075         0.946248       0.950049      0.013403  \n",
       "1300 3.0     0.075         0.944640       0.948633      0.013620  \n",
       "1350 3.0     0.075         0.946292       0.950033      0.013351  \n",
       "1300 3.5     0.075         0.944655       0.948590      0.013574  \n",
       "1350 3.5     0.075         0.946292       0.949971      0.013303  \n",
       "             0.025         0.853740       0.864679      0.022874  \n",
       "     3.0     0.025         0.853600       0.864381      0.022900  \n",
       "     2.5     0.025         0.853418       0.864088      0.022932  \n",
       "1300 3.5     0.025         0.852270       0.863061      0.023010  \n",
       "     3.0     0.025         0.852106       0.862854      0.023009  \n",
       "     2.5     0.025         0.851616       0.862472      0.023111  \n",
       "1250 3.5     0.025         0.850458       0.861430      0.023172  \n",
       "     3.0     0.025         0.850579       0.861215      0.023150  \n",
       "     2.5     0.025         0.850284       0.860910      0.023202  \n",
       "\n",
       "[27 rows x 54 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>split0_test_neg_mean_squared_error</th>\n      <th>split1_test_neg_mean_squared_error</th>\n      <th>split2_test_neg_mean_squared_error</th>\n      <th>split3_test_neg_mean_squared_error</th>\n      <th>split4_test_neg_mean_squared_error</th>\n      <th>split5_test_neg_mean_squared_error</th>\n      <th>...</th>\n      <th>split2_train_r2</th>\n      <th>split3_train_r2</th>\n      <th>split4_train_r2</th>\n      <th>split5_train_r2</th>\n      <th>split6_train_r2</th>\n      <th>split7_train_r2</th>\n      <th>split8_train_r2</th>\n      <th>split9_train_r2</th>\n      <th>mean_train_r2</th>\n      <th>std_train_r2</th>\n    </tr>\n    <tr>\n      <th>C</th>\n      <th>epsilon</th>\n      <th>gamma</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1300</th>\n      <th>3.0</th>\n      <th>0.050</th>\n      <td>0.829903</td>\n      <td>0.065854</td>\n      <td>0.051771</td>\n      <td>0.017056</td>\n      <td>-1145.356536</td>\n      <td>-1049.564833</td>\n      <td>-804.734634</td>\n      <td>-1696.723513</td>\n      <td>-721.535961</td>\n      <td>-873.827602</td>\n      <td>...</td>\n      <td>0.916324</td>\n      <td>0.917709</td>\n      <td>0.912960</td>\n      <td>0.917079</td>\n      <td>0.911893</td>\n      <td>0.912837</td>\n      <td>0.971102</td>\n      <td>0.912319</td>\n      <td>0.919711</td>\n      <td>0.017319</td>\n    </tr>\n    <tr>\n      <th>3.5</th>\n      <th>0.050</th>\n      <td>0.775498</td>\n      <td>0.072712</td>\n      <td>0.045983</td>\n      <td>0.012798</td>\n      <td>-1144.199280</td>\n      <td>-1047.412773</td>\n      <td>-804.461785</td>\n      <td>-1697.011940</td>\n      <td>-723.558499</td>\n      <td>-875.512598</td>\n      <td>...</td>\n      <td>0.916312</td>\n      <td>0.917602</td>\n      <td>0.912928</td>\n      <td>0.917002</td>\n      <td>0.911828</td>\n      <td>0.912817</td>\n      <td>0.971109</td>\n      <td>0.912334</td>\n      <td>0.919683</td>\n      <td>0.017325</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1350</th>\n      <th>2.5</th>\n      <th>0.050</th>\n      <td>0.801991</td>\n      <td>0.111988</td>\n      <td>0.044781</td>\n      <td>0.004944</td>\n      <td>-1151.214365</td>\n      <td>-1056.226769</td>\n      <td>-819.434599</td>\n      <td>-1716.517109</td>\n      <td>-726.533684</td>\n      <td>-874.368429</td>\n      <td>...</td>\n      <td>0.918043</td>\n      <td>0.919141</td>\n      <td>0.914532</td>\n      <td>0.918621</td>\n      <td>0.913385</td>\n      <td>0.914385</td>\n      <td>0.972150</td>\n      <td>0.913824</td>\n      <td>0.921222</td>\n      <td>0.017163</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <th>0.050</th>\n      <td>0.789651</td>\n      <td>0.074729</td>\n      <td>0.053531</td>\n      <td>0.020557</td>\n      <td>-1151.771193</td>\n      <td>-1051.400180</td>\n      <td>-818.318093</td>\n      <td>-1720.390317</td>\n      <td>-726.648454</td>\n      <td>-877.946861</td>\n      <td>...</td>\n      <td>0.918182</td>\n      <td>0.918998</td>\n      <td>0.914469</td>\n      <td>0.918408</td>\n      <td>0.913316</td>\n      <td>0.914350</td>\n      <td>0.972246</td>\n      <td>0.913891</td>\n      <td>0.921221</td>\n      <td>0.017186</td>\n    </tr>\n    <tr>\n      <th>3.5</th>\n      <th>0.050</th>\n      <td>0.708292</td>\n      <td>0.070458</td>\n      <td>0.043272</td>\n      <td>0.009351</td>\n      <td>-1150.417402</td>\n      <td>-1052.949864</td>\n      <td>-819.503605</td>\n      <td>-1717.757520</td>\n      <td>-728.269199</td>\n      <td>-873.917502</td>\n      <td>...</td>\n      <td>0.918198</td>\n      <td>0.918994</td>\n      <td>0.914272</td>\n      <td>0.918353</td>\n      <td>0.913196</td>\n      <td>0.914324</td>\n      <td>0.972213</td>\n      <td>0.913845</td>\n      <td>0.921177</td>\n      <td>0.017187</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <th>2.5</th>\n      <th>0.050</th>\n      <td>0.784792</td>\n      <td>0.058641</td>\n      <td>0.047649</td>\n      <td>0.011683</td>\n      <td>-1148.628297</td>\n      <td>-1053.856836</td>\n      <td>-807.502433</td>\n      <td>-1702.327707</td>\n      <td>-719.991005</td>\n      <td>-874.059731</td>\n      <td>...</td>\n      <td>0.916293</td>\n      <td>0.917710</td>\n      <td>0.913211</td>\n      <td>0.917179</td>\n      <td>0.912092</td>\n      <td>0.912875</td>\n      <td>0.971000</td>\n      <td>0.912235</td>\n      <td>0.919737</td>\n      <td>0.017284</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1250</th>\n      <th>3.0</th>\n      <th>0.050</th>\n      <td>0.772920</td>\n      <td>0.073513</td>\n      <td>0.059451</td>\n      <td>0.020627</td>\n      <td>-1137.752021</td>\n      <td>-1046.046100</td>\n      <td>-791.236216</td>\n      <td>-1678.450064</td>\n      <td>-716.896878</td>\n      <td>-874.242000</td>\n      <td>...</td>\n      <td>0.914477</td>\n      <td>0.916135</td>\n      <td>0.911377</td>\n      <td>0.915588</td>\n      <td>0.910524</td>\n      <td>0.911278</td>\n      <td>0.969841</td>\n      <td>0.910692</td>\n      <td>0.918102</td>\n      <td>0.017451</td>\n    </tr>\n    <tr>\n      <th>3.5</th>\n      <th>0.050</th>\n      <td>0.747952</td>\n      <td>0.108606</td>\n      <td>0.050576</td>\n      <td>0.013313</td>\n      <td>-1139.756403</td>\n      <td>-1046.769176</td>\n      <td>-790.159228</td>\n      <td>-1676.512710</td>\n      <td>-717.759729</td>\n      <td>-874.700392</td>\n      <td>...</td>\n      <td>0.914520</td>\n      <td>0.916111</td>\n      <td>0.911323</td>\n      <td>0.915468</td>\n      <td>0.910397</td>\n      <td>0.911224</td>\n      <td>0.969928</td>\n      <td>0.910744</td>\n      <td>0.918075</td>\n      <td>0.017485</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">2.5</th>\n      <th>0.050</th>\n      <td>0.836529</td>\n      <td>0.125782</td>\n      <td>0.051178</td>\n      <td>0.013872</td>\n      <td>-1133.115910</td>\n      <td>-1049.344059</td>\n      <td>-795.583227</td>\n      <td>-1680.255812</td>\n      <td>-713.863298</td>\n      <td>-871.837862</td>\n      <td>...</td>\n      <td>0.914523</td>\n      <td>0.916196</td>\n      <td>0.911599</td>\n      <td>0.915554</td>\n      <td>0.910649</td>\n      <td>0.911326</td>\n      <td>0.969818</td>\n      <td>0.910670</td>\n      <td>0.918155</td>\n      <td>0.017425</td>\n    </tr>\n    <tr>\n      <th>0.075</th>\n      <td>0.768437</td>\n      <td>0.071870</td>\n      <td>0.057682</td>\n      <td>0.017425</td>\n      <td>-1260.234665</td>\n      <td>-1139.704693</td>\n      <td>-1144.569273</td>\n      <td>-1688.277930</td>\n      <td>-744.979050</td>\n      <td>-892.220052</td>\n      <td>...</td>\n      <td>0.948569</td>\n      <td>0.945046</td>\n      <td>0.941287</td>\n      <td>0.942875</td>\n      <td>0.936932</td>\n      <td>0.940794</td>\n      <td>0.988044</td>\n      <td>0.942703</td>\n      <td>0.947085</td>\n      <td>0.013941</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <th>0.075</th>\n      <td>0.743784</td>\n      <td>0.140810</td>\n      <td>0.045379</td>\n      <td>0.008711</td>\n      <td>-1263.921834</td>\n      <td>-1135.041694</td>\n      <td>-1150.157344</td>\n      <td>-1683.932803</td>\n      <td>-746.487257</td>\n      <td>-894.094790</td>\n      <td>...</td>\n      <td>0.948568</td>\n      <td>0.945084</td>\n      <td>0.941243</td>\n      <td>0.942941</td>\n      <td>0.936843</td>\n      <td>0.940819</td>\n      <td>0.987888</td>\n      <td>0.942770</td>\n      <td>0.947078</td>\n      <td>0.013897</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <th>2.5</th>\n      <th>0.075</th>\n      <td>0.834043</td>\n      <td>0.062294</td>\n      <td>0.069565</td>\n      <td>0.022368</td>\n      <td>-1278.004064</td>\n      <td>-1133.337494</td>\n      <td>-1192.452726</td>\n      <td>-1693.225206</td>\n      <td>-745.092593</td>\n      <td>-893.970204</td>\n      <td>...</td>\n      <td>0.950243</td>\n      <td>0.946591</td>\n      <td>0.942969</td>\n      <td>0.944410</td>\n      <td>0.938525</td>\n      <td>0.942356</td>\n      <td>0.988745</td>\n      <td>0.944606</td>\n      <td>0.948650</td>\n      <td>0.013661</td>\n    </tr>\n    <tr>\n      <th>1250</th>\n      <th>3.5</th>\n      <th>0.075</th>\n      <td>0.779161</td>\n      <td>0.087002</td>\n      <td>0.050286</td>\n      <td>0.015259</td>\n      <td>-1268.771092</td>\n      <td>-1131.536855</td>\n      <td>-1158.782086</td>\n      <td>-1680.932076</td>\n      <td>-747.962572</td>\n      <td>-896.455363</td>\n      <td>...</td>\n      <td>0.948528</td>\n      <td>0.945068</td>\n      <td>0.941189</td>\n      <td>0.942974</td>\n      <td>0.936736</td>\n      <td>0.940785</td>\n      <td>0.987695</td>\n      <td>0.942770</td>\n      <td>0.947031</td>\n      <td>0.013852</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <th>2.5</th>\n      <th>0.075</th>\n      <td>0.681579</td>\n      <td>0.059522</td>\n      <td>0.045985</td>\n      <td>0.007430</td>\n      <td>-1295.680843</td>\n      <td>-1125.755755</td>\n      <td>-1202.785831</td>\n      <td>-1700.041110</td>\n      <td>-747.068750</td>\n      <td>-896.668196</td>\n      <td>...</td>\n      <td>0.951287</td>\n      <td>0.948079</td>\n      <td>0.944515</td>\n      <td>0.945841</td>\n      <td>0.940055</td>\n      <td>0.943794</td>\n      <td>0.989421</td>\n      <td>0.946248</td>\n      <td>0.950049</td>\n      <td>0.013403</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <th>3.0</th>\n      <th>0.075</th>\n      <td>0.803412</td>\n      <td>0.088220</td>\n      <td>0.058484</td>\n      <td>0.022010</td>\n      <td>-1281.983027</td>\n      <td>-1127.781546</td>\n      <td>-1201.327942</td>\n      <td>-1690.355162</td>\n      <td>-747.441252</td>\n      <td>-896.559808</td>\n      <td>...</td>\n      <td>0.950231</td>\n      <td>0.946624</td>\n      <td>0.942956</td>\n      <td>0.944473</td>\n      <td>0.938453</td>\n      <td>0.942333</td>\n      <td>0.988593</td>\n      <td>0.944640</td>\n      <td>0.948633</td>\n      <td>0.013620</td>\n    </tr>\n    <tr>\n      <th>1350</th>\n      <th>3.0</th>\n      <th>0.075</th>\n      <td>0.766438</td>\n      <td>0.094365</td>\n      <td>0.050069</td>\n      <td>0.012830</td>\n      <td>-1300.596133</td>\n      <td>-1121.855807</td>\n      <td>-1207.355622</td>\n      <td>-1697.712410</td>\n      <td>-748.546346</td>\n      <td>-897.992262</td>\n      <td>...</td>\n      <td>0.951218</td>\n      <td>0.948072</td>\n      <td>0.944552</td>\n      <td>0.945910</td>\n      <td>0.939966</td>\n      <td>0.943807</td>\n      <td>0.989241</td>\n      <td>0.946292</td>\n      <td>0.950033</td>\n      <td>0.013351</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <th>3.5</th>\n      <th>0.075</th>\n      <td>0.789260</td>\n      <td>0.084868</td>\n      <td>0.048982</td>\n      <td>0.011335</td>\n      <td>-1285.538748</td>\n      <td>-1124.025170</td>\n      <td>-1209.554048</td>\n      <td>-1688.070185</td>\n      <td>-749.073198</td>\n      <td>-897.983430</td>\n      <td>...</td>\n      <td>0.950180</td>\n      <td>0.946621</td>\n      <td>0.942907</td>\n      <td>0.944510</td>\n      <td>0.938349</td>\n      <td>0.942311</td>\n      <td>0.988400</td>\n      <td>0.944655</td>\n      <td>0.948590</td>\n      <td>0.013574</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1350</th>\n      <th rowspan=\"2\" valign=\"top\">3.5</th>\n      <th>0.075</th>\n      <td>0.639023</td>\n      <td>0.039574</td>\n      <td>0.041279</td>\n      <td>0.008092</td>\n      <td>-1302.373110</td>\n      <td>-1119.038598</td>\n      <td>-1212.786558</td>\n      <td>-1694.246215</td>\n      <td>-750.943737</td>\n      <td>-899.578797</td>\n      <td>...</td>\n      <td>0.951107</td>\n      <td>0.947966</td>\n      <td>0.944511</td>\n      <td>0.945933</td>\n      <td>0.939882</td>\n      <td>0.943779</td>\n      <td>0.989038</td>\n      <td>0.946292</td>\n      <td>0.949971</td>\n      <td>0.013303</td>\n    </tr>\n    <tr>\n      <th>0.025</th>\n      <td>0.697495</td>\n      <td>0.108844</td>\n      <td>0.044879</td>\n      <td>0.012536</td>\n      <td>-1084.677640</td>\n      <td>-872.031071</td>\n      <td>-706.124831</td>\n      <td>-1572.458518</td>\n      <td>-873.568759</td>\n      <td>-854.657564</td>\n      <td>...</td>\n      <td>0.856845</td>\n      <td>0.861305</td>\n      <td>0.856520</td>\n      <td>0.861791</td>\n      <td>0.855725</td>\n      <td>0.855411</td>\n      <td>0.932837</td>\n      <td>0.853740</td>\n      <td>0.864679</td>\n      <td>0.022874</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <th>0.025</th>\n      <td>0.791283</td>\n      <td>0.062725</td>\n      <td>0.044076</td>\n      <td>0.008369</td>\n      <td>-1081.785910</td>\n      <td>-875.964407</td>\n      <td>-703.307260</td>\n      <td>-1578.353972</td>\n      <td>-871.784271</td>\n      <td>-852.966550</td>\n      <td>...</td>\n      <td>0.856380</td>\n      <td>0.861148</td>\n      <td>0.856138</td>\n      <td>0.861345</td>\n      <td>0.855848</td>\n      <td>0.855381</td>\n      <td>0.932623</td>\n      <td>0.853600</td>\n      <td>0.864381</td>\n      <td>0.022900</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <th>0.025</th>\n      <td>0.898503</td>\n      <td>0.102372</td>\n      <td>0.058574</td>\n      <td>0.022573</td>\n      <td>-1083.066569</td>\n      <td>-874.134170</td>\n      <td>-703.073201</td>\n      <td>-1577.021024</td>\n      <td>-868.051209</td>\n      <td>-852.674201</td>\n      <td>...</td>\n      <td>0.855969</td>\n      <td>0.860961</td>\n      <td>0.856049</td>\n      <td>0.860974</td>\n      <td>0.855603</td>\n      <td>0.854582</td>\n      <td>0.932438</td>\n      <td>0.853418</td>\n      <td>0.864088</td>\n      <td>0.022932</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1300</th>\n      <th>3.5</th>\n      <th>0.025</th>\n      <td>0.776980</td>\n      <td>0.054748</td>\n      <td>0.041300</td>\n      <td>0.004949</td>\n      <td>-1083.053677</td>\n      <td>-870.366957</td>\n      <td>-703.389330</td>\n      <td>-1569.970893</td>\n      <td>-875.552211</td>\n      <td>-850.274942</td>\n      <td>...</td>\n      <td>0.855124</td>\n      <td>0.859518</td>\n      <td>0.854898</td>\n      <td>0.859903</td>\n      <td>0.854526</td>\n      <td>0.853423</td>\n      <td>0.931659</td>\n      <td>0.852270</td>\n      <td>0.863061</td>\n      <td>0.023010</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <th>0.025</th>\n      <td>0.804169</td>\n      <td>0.086424</td>\n      <td>0.055181</td>\n      <td>0.017542</td>\n      <td>-1088.766989</td>\n      <td>-874.993231</td>\n      <td>-703.577293</td>\n      <td>-1569.759123</td>\n      <td>-876.359757</td>\n      <td>-849.926472</td>\n      <td>...</td>\n      <td>0.855097</td>\n      <td>0.859316</td>\n      <td>0.854479</td>\n      <td>0.859772</td>\n      <td>0.854306</td>\n      <td>0.853228</td>\n      <td>0.931448</td>\n      <td>0.852106</td>\n      <td>0.862854</td>\n      <td>0.023009</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <th>0.025</th>\n      <td>0.669215</td>\n      <td>0.035570</td>\n      <td>0.039477</td>\n      <td>0.002148</td>\n      <td>-1089.490943</td>\n      <td>-872.199547</td>\n      <td>-703.674034</td>\n      <td>-1575.756535</td>\n      <td>-872.225229</td>\n      <td>-850.315923</td>\n      <td>...</td>\n      <td>0.854661</td>\n      <td>0.859218</td>\n      <td>0.854307</td>\n      <td>0.859208</td>\n      <td>0.853783</td>\n      <td>0.852754</td>\n      <td>0.931367</td>\n      <td>0.851616</td>\n      <td>0.862472</td>\n      <td>0.023111</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1250</th>\n      <th>3.5</th>\n      <th>0.025</th>\n      <td>0.671217</td>\n      <td>0.044765</td>\n      <td>0.044515</td>\n      <td>0.010016</td>\n      <td>-1083.375338</td>\n      <td>-869.388026</td>\n      <td>-701.572350</td>\n      <td>-1565.311624</td>\n      <td>-880.941750</td>\n      <td>-851.748339</td>\n      <td>...</td>\n      <td>0.853684</td>\n      <td>0.857529</td>\n      <td>0.853472</td>\n      <td>0.858559</td>\n      <td>0.852756</td>\n      <td>0.851642</td>\n      <td>0.930503</td>\n      <td>0.850458</td>\n      <td>0.861430</td>\n      <td>0.023172</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <th>0.025</th>\n      <td>0.692767</td>\n      <td>0.056127</td>\n      <td>0.048517</td>\n      <td>0.018406</td>\n      <td>-1085.041436</td>\n      <td>-870.200134</td>\n      <td>-702.686740</td>\n      <td>-1572.494166</td>\n      <td>-874.981488</td>\n      <td>-847.745252</td>\n      <td>...</td>\n      <td>0.853291</td>\n      <td>0.857425</td>\n      <td>0.853104</td>\n      <td>0.858132</td>\n      <td>0.852648</td>\n      <td>0.851405</td>\n      <td>0.930238</td>\n      <td>0.850579</td>\n      <td>0.861215</td>\n      <td>0.023150</td>\n    </tr>\n    <tr>\n      <th>2.5</th>\n      <th>0.025</th>\n      <td>0.735128</td>\n      <td>0.038044</td>\n      <td>0.040202</td>\n      <td>0.003176</td>\n      <td>-1085.846536</td>\n      <td>-879.561743</td>\n      <td>-706.075019</td>\n      <td>-1568.076677</td>\n      <td>-874.892014</td>\n      <td>-848.179742</td>\n      <td>...</td>\n      <td>0.853081</td>\n      <td>0.857320</td>\n      <td>0.852658</td>\n      <td>0.857796</td>\n      <td>0.852260</td>\n      <td>0.851227</td>\n      <td>0.930085</td>\n      <td>0.850284</td>\n      <td>0.860910</td>\n      <td>0.023202</td>\n    </tr>\n  </tbody>\n</table>\n<p>27 rows × 54 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "gsradial1.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsradial1.save('models/SVR_Radial.p')"
   ]
  },
  {
   "source": [
    "# SVR(Linear)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVR(kernel='linear', max_iter=10000), n_jobs=1,\n",
       "             param_grid={'C': [0.8],\n",
       "                         'epsilon': array([0.0015, 0.0025, 0.0035])},\n",
       "             refit='neg_mean_squared_error', return_train_score=True,\n",
       "             scoring=['neg_mean_squared_error', 'r2'], verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "modell = SVR(kernel=\"linear\",max_iter= 10000)\n",
    "C = [0.8]\n",
    "epsilon = np.linspace(0.0015,0.0035,3)\n",
    "paraml = {'C':C,'epsilon' : epsilon}\n",
    "\n",
    "gsrl =StandardizedGridSearchCV(modell,paraml, n_jobs=1,verbose = False)\n",
    "\n",
    "gsrl.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C    epsilon\n",
       "0.8  0.0025    -3578.632569\n",
       "     0.0035    -3578.709545\n",
       "     0.0015    -3578.776894\n",
       "Name: mean_test_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "gsrl.results['mean_test_neg_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C    epsilon\n",
       "0.8  0.0025    -3516.875240\n",
       "     0.0035    -3516.920243\n",
       "     0.0015    -3516.828511\n",
       "Name: mean_train_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "gsrl.results['mean_train_neg_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "C   epsilon                                                                 \n",
       "0.8 0.0025        0.455130      0.038324         0.046281        0.014309   \n",
       "    0.0035        0.446040      0.054378         0.046272        0.013044   \n",
       "    0.0015        0.471418      0.068440         0.042885        0.009606   \n",
       "\n",
       "             split0_test_neg_mean_squared_error  \\\n",
       "C   epsilon                                       \n",
       "0.8 0.0025                         -1377.381634   \n",
       "    0.0035                         -1378.283037   \n",
       "    0.0015                         -1377.376173   \n",
       "\n",
       "             split1_test_neg_mean_squared_error  \\\n",
       "C   epsilon                                       \n",
       "0.8 0.0025                         -1655.880211   \n",
       "    0.0035                         -1655.943415   \n",
       "    0.0015                         -1655.907202   \n",
       "\n",
       "             split2_test_neg_mean_squared_error  \\\n",
       "C   epsilon                                       \n",
       "0.8 0.0025                         -1244.456380   \n",
       "    0.0035                         -1244.467185   \n",
       "    0.0015                         -1244.443386   \n",
       "\n",
       "             split3_test_neg_mean_squared_error  \\\n",
       "C   epsilon                                       \n",
       "0.8 0.0025                         -1986.674280   \n",
       "    0.0035                         -1986.670237   \n",
       "    0.0015                         -1986.557420   \n",
       "\n",
       "             split4_test_neg_mean_squared_error  \\\n",
       "C   epsilon                                       \n",
       "0.8 0.0025                         -5156.440701   \n",
       "    0.0035                         -5156.220601   \n",
       "    0.0015                         -5158.008415   \n",
       "\n",
       "             split5_test_neg_mean_squared_error  ...  split2_train_r2  \\\n",
       "C   epsilon                                      ...                    \n",
       "0.8 0.0025                         -1647.177003  ...         0.649099   \n",
       "    0.0035                         -1647.156394  ...         0.649100   \n",
       "    0.0015                         -1647.179011  ...         0.649099   \n",
       "\n",
       "             split3_train_r2  split4_train_r2  split5_train_r2  \\\n",
       "C   epsilon                                                      \n",
       "0.8 0.0025          0.643515         0.684541         0.655278   \n",
       "    0.0035          0.643516         0.684544         0.655280   \n",
       "    0.0015          0.643536         0.684574         0.655277   \n",
       "\n",
       "             split6_train_r2  split7_train_r2  split8_train_r2  \\\n",
       "C   epsilon                                                      \n",
       "0.8 0.0025          0.642390         0.639293         0.740840   \n",
       "    0.0035          0.642391         0.639298         0.740841   \n",
       "    0.0015          0.642390         0.639288         0.740839   \n",
       "\n",
       "             split9_train_r2  mean_train_r2  std_train_r2  \n",
       "C   epsilon                                                \n",
       "0.8 0.0025          0.637252       0.657308      0.030849  \n",
       "    0.0035          0.637254       0.657304      0.030853  \n",
       "    0.0015          0.637249       0.657313      0.030852  \n",
       "\n",
       "[3 rows x 54 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>split0_test_neg_mean_squared_error</th>\n      <th>split1_test_neg_mean_squared_error</th>\n      <th>split2_test_neg_mean_squared_error</th>\n      <th>split3_test_neg_mean_squared_error</th>\n      <th>split4_test_neg_mean_squared_error</th>\n      <th>split5_test_neg_mean_squared_error</th>\n      <th>...</th>\n      <th>split2_train_r2</th>\n      <th>split3_train_r2</th>\n      <th>split4_train_r2</th>\n      <th>split5_train_r2</th>\n      <th>split6_train_r2</th>\n      <th>split7_train_r2</th>\n      <th>split8_train_r2</th>\n      <th>split9_train_r2</th>\n      <th>mean_train_r2</th>\n      <th>std_train_r2</th>\n    </tr>\n    <tr>\n      <th>C</th>\n      <th>epsilon</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">0.8</th>\n      <th>0.0025</th>\n      <td>0.455130</td>\n      <td>0.038324</td>\n      <td>0.046281</td>\n      <td>0.014309</td>\n      <td>-1377.381634</td>\n      <td>-1655.880211</td>\n      <td>-1244.456380</td>\n      <td>-1986.674280</td>\n      <td>-5156.440701</td>\n      <td>-1647.177003</td>\n      <td>...</td>\n      <td>0.649099</td>\n      <td>0.643515</td>\n      <td>0.684541</td>\n      <td>0.655278</td>\n      <td>0.642390</td>\n      <td>0.639293</td>\n      <td>0.740840</td>\n      <td>0.637252</td>\n      <td>0.657308</td>\n      <td>0.030849</td>\n    </tr>\n    <tr>\n      <th>0.0035</th>\n      <td>0.446040</td>\n      <td>0.054378</td>\n      <td>0.046272</td>\n      <td>0.013044</td>\n      <td>-1378.283037</td>\n      <td>-1655.943415</td>\n      <td>-1244.467185</td>\n      <td>-1986.670237</td>\n      <td>-5156.220601</td>\n      <td>-1647.156394</td>\n      <td>...</td>\n      <td>0.649100</td>\n      <td>0.643516</td>\n      <td>0.684544</td>\n      <td>0.655280</td>\n      <td>0.642391</td>\n      <td>0.639298</td>\n      <td>0.740841</td>\n      <td>0.637254</td>\n      <td>0.657304</td>\n      <td>0.030853</td>\n    </tr>\n    <tr>\n      <th>0.0015</th>\n      <td>0.471418</td>\n      <td>0.068440</td>\n      <td>0.042885</td>\n      <td>0.009606</td>\n      <td>-1377.376173</td>\n      <td>-1655.907202</td>\n      <td>-1244.443386</td>\n      <td>-1986.557420</td>\n      <td>-5158.008415</td>\n      <td>-1647.179011</td>\n      <td>...</td>\n      <td>0.649099</td>\n      <td>0.643536</td>\n      <td>0.684574</td>\n      <td>0.655277</td>\n      <td>0.642390</td>\n      <td>0.639288</td>\n      <td>0.740839</td>\n      <td>0.637249</td>\n      <td>0.657313</td>\n      <td>0.030852</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 54 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "gsrl.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsrl.save('models/SVR_Linear.p')"
   ]
  },
  {
   "source": [
    "# SVR(Poly)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVR(kernel='poly', max_iter=10000), n_jobs=1,\n",
       "             param_grid={'C': [1], 'degree': [2], 'epsilon': [0.8],\n",
       "                         'gamma': [1]},\n",
       "             refit='neg_mean_squared_error', return_train_score=True,\n",
       "             scoring=['neg_mean_squared_error', 'r2'], verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "modelp = SVR(kernel=\"poly\",max_iter= 10000)\n",
    "\n",
    "degree = [2]\n",
    "gamma = [1]\n",
    "C =  [1]\n",
    "epsilon = [0.8]\n",
    "paramp = {'C' :C, 'gamma': gamma, 'epsilon' : epsilon, 'degree': degree}\n",
    "\n",
    "gspoly = StandardizedGridSearchCV(modelp,paramp, n_jobs=1,verbose = False)\n",
    "\n",
    "gspoly.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C  degree  epsilon  gamma\n",
       "1  2       0.8      1       -2772.670671\n",
       "Name: mean_test_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "gspoly.results['mean_test_neg_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C  degree  epsilon  gamma\n",
       "1  2       0.8      1       -2300.061432\n",
       "Name: mean_train_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "gspoly.results['mean_train_neg_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "C degree epsilon gamma                                                 \n",
       "1 2      0.8     1           0.609288      0.032286         0.035485   \n",
       "\n",
       "                        std_score_time  split0_test_neg_mean_squared_error  \\\n",
       "C degree epsilon gamma                                                       \n",
       "1 2      0.8     1            0.011427                         -1225.74475   \n",
       "\n",
       "                        split1_test_neg_mean_squared_error  \\\n",
       "C degree epsilon gamma                                       \n",
       "1 2      0.8     1                            -1215.141971   \n",
       "\n",
       "                        split2_test_neg_mean_squared_error  \\\n",
       "C degree epsilon gamma                                       \n",
       "1 2      0.8     1                            -1435.334667   \n",
       "\n",
       "                        split3_test_neg_mean_squared_error  \\\n",
       "C degree epsilon gamma                                       \n",
       "1 2      0.8     1                            -2206.196579   \n",
       "\n",
       "                        split4_test_neg_mean_squared_error  \\\n",
       "C degree epsilon gamma                                       \n",
       "1 2      0.8     1                            -1882.971472   \n",
       "\n",
       "                        split5_test_neg_mean_squared_error  ...  \\\n",
       "C degree epsilon gamma                                      ...   \n",
       "1 2      0.8     1                            -1404.909794  ...   \n",
       "\n",
       "                        split2_train_r2  split3_train_r2  split4_train_r2  \\\n",
       "C degree epsilon gamma                                                      \n",
       "1 2      0.8     1             0.757982         0.788989         0.770996   \n",
       "\n",
       "                        split5_train_r2  split6_train_r2  split7_train_r2  \\\n",
       "C degree epsilon gamma                                                      \n",
       "1 2      0.8     1             0.782373         0.766056         0.760847   \n",
       "\n",
       "                        split8_train_r2  split9_train_r2  mean_train_r2  \\\n",
       "C degree epsilon gamma                                                    \n",
       "1 2      0.8     1             0.849643         0.779153       0.776268   \n",
       "\n",
       "                        std_train_r2  \n",
       "C degree epsilon gamma                \n",
       "1 2      0.8     1          0.028873  \n",
       "\n",
       "[1 rows x 54 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>split0_test_neg_mean_squared_error</th>\n      <th>split1_test_neg_mean_squared_error</th>\n      <th>split2_test_neg_mean_squared_error</th>\n      <th>split3_test_neg_mean_squared_error</th>\n      <th>split4_test_neg_mean_squared_error</th>\n      <th>split5_test_neg_mean_squared_error</th>\n      <th>...</th>\n      <th>split2_train_r2</th>\n      <th>split3_train_r2</th>\n      <th>split4_train_r2</th>\n      <th>split5_train_r2</th>\n      <th>split6_train_r2</th>\n      <th>split7_train_r2</th>\n      <th>split8_train_r2</th>\n      <th>split9_train_r2</th>\n      <th>mean_train_r2</th>\n      <th>std_train_r2</th>\n    </tr>\n    <tr>\n      <th>C</th>\n      <th>degree</th>\n      <th>epsilon</th>\n      <th>gamma</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <th>2</th>\n      <th>0.8</th>\n      <th>1</th>\n      <td>0.609288</td>\n      <td>0.032286</td>\n      <td>0.035485</td>\n      <td>0.011427</td>\n      <td>-1225.74475</td>\n      <td>-1215.141971</td>\n      <td>-1435.334667</td>\n      <td>-2206.196579</td>\n      <td>-1882.971472</td>\n      <td>-1404.909794</td>\n      <td>...</td>\n      <td>0.757982</td>\n      <td>0.788989</td>\n      <td>0.770996</td>\n      <td>0.782373</td>\n      <td>0.766056</td>\n      <td>0.760847</td>\n      <td>0.849643</td>\n      <td>0.779153</td>\n      <td>0.776268</td>\n      <td>0.028873</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 54 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "gspoly.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspoly.save('models/SVR_Poly.p')"
   ]
  },
  {
   "source": [
    "# SVR (Sigmoid)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "C:\\Users\\Isaac\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVR(kernel='sigmoid', max_iter=10000), n_jobs=1,\n",
       "             param_grid={'C': [900, 1000, 1100], 'epsilon': [0.8, 1, 1.2],\n",
       "                         'gamma': [0.001]},\n",
       "             refit='neg_mean_squared_error', return_train_score=True,\n",
       "             scoring=['neg_mean_squared_error', 'r2'], verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "modelS = SVR(kernel='sigmoid',max_iter= 10000)\n",
    "\n",
    "gamma = [0.001]\n",
    "C =  [900,1000,1100]\n",
    "epsilon = [0.8,1,1.2]\n",
    "paramS = {'C' :C, 'gamma': gamma, 'epsilon' : epsilon}\n",
    "\n",
    "gssigmoid = StandardizedGridSearchCV(modelS,paramS, n_jobs=1,verbose = False)\n",
    "\n",
    "gssigmoid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C     epsilon  gamma\n",
       "900   1.2      0.001   -3567.454758\n",
       "      0.8      0.001   -3569.489120\n",
       "      1.0      0.001   -3570.395586\n",
       "1000  1.2      0.001   -3573.973378\n",
       "      1.0      0.001   -3575.700464\n",
       "1100  1.2      0.001   -3577.529373\n",
       "1000  0.8      0.001   -3578.730801\n",
       "1100  1.0      0.001   -3580.557704\n",
       "      0.8      0.001   -3581.187094\n",
       "Name: mean_test_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "gssigmoid.results['mean_test_neg_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "C     epsilon  gamma\n",
       "900   1.2      0.001   -3532.227237\n",
       "      0.8      0.001   -3533.167717\n",
       "      1.0      0.001   -3532.740324\n",
       "1000  1.2      0.001   -3535.742708\n",
       "      1.0      0.001   -3536.995272\n",
       "1100  1.2      0.001   -3540.470196\n",
       "1000  0.8      0.001   -3537.655253\n",
       "1100  1.0      0.001   -3541.685555\n",
       "      0.8      0.001   -3542.450081\n",
       "Name: mean_train_neg_mean_squared_error, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "gssigmoid.results['mean_train_neg_mean_squared_error']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "C    epsilon gamma                                                 \n",
       "900  1.2     0.001       0.494813      0.033647         0.054565   \n",
       "     0.8     0.001       0.502707      0.045648         0.044878   \n",
       "     1.0     0.001       0.514203      0.059108         0.052475   \n",
       "1000 1.2     0.001       0.503312      0.044865         0.050578   \n",
       "     1.0     0.001       0.513101      0.057145         0.049271   \n",
       "1100 1.2     0.001       0.523688      0.055016         0.058477   \n",
       "1000 0.8     0.001       0.528805      0.049323         0.046268   \n",
       "1100 1.0     0.001       0.479917      0.020635         0.041684   \n",
       "     0.8     0.001       0.487814      0.039728         0.058160   \n",
       "\n",
       "                    std_score_time  split0_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                                       \n",
       "900  1.2     0.001        0.019347                        -1379.713343   \n",
       "     0.8     0.001        0.008966                        -1379.725193   \n",
       "     1.0     0.001        0.013371                        -1380.099748   \n",
       "1000 1.2     0.001        0.021049                        -1375.678290   \n",
       "     1.0     0.001        0.010598                        -1377.194540   \n",
       "1100 1.2     0.001        0.021942                        -1372.068257   \n",
       "1000 0.8     0.001        0.008795                        -1374.876997   \n",
       "1100 1.0     0.001        0.003527                        -1370.285281   \n",
       "     0.8     0.001        0.020757                        -1371.535973   \n",
       "\n",
       "                    split1_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "900  1.2     0.001                        -1661.900299   \n",
       "     0.8     0.001                        -1659.945396   \n",
       "     1.0     0.001                        -1659.799173   \n",
       "1000 1.2     0.001                        -1637.074825   \n",
       "     1.0     0.001                        -1639.815569   \n",
       "1100 1.2     0.001                        -1628.848020   \n",
       "1000 0.8     0.001                        -1639.871308   \n",
       "1100 1.0     0.001                        -1633.166410   \n",
       "     0.8     0.001                        -1636.899866   \n",
       "\n",
       "                    split2_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "900  1.2     0.001                        -1272.622116   \n",
       "     0.8     0.001                        -1271.592488   \n",
       "     1.0     0.001                        -1272.156979   \n",
       "1000 1.2     0.001                        -1269.449124   \n",
       "     1.0     0.001                        -1269.418890   \n",
       "1100 1.2     0.001                        -1267.648886   \n",
       "1000 0.8     0.001                        -1271.208021   \n",
       "1100 1.0     0.001                        -1267.301867   \n",
       "     0.8     0.001                        -1266.741891   \n",
       "\n",
       "                    split3_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "900  1.2     0.001                        -2019.141156   \n",
       "     0.8     0.001                        -2018.294323   \n",
       "     1.0     0.001                        -2014.959455   \n",
       "1000 1.2     0.001                        -2018.776845   \n",
       "     1.0     0.001                        -2016.211512   \n",
       "1100 1.2     0.001                        -2014.375844   \n",
       "1000 0.8     0.001                        -2019.171843   \n",
       "1100 1.0     0.001                        -2011.537258   \n",
       "     0.8     0.001                        -2015.871834   \n",
       "\n",
       "                    split4_test_neg_mean_squared_error  \\\n",
       "C    epsilon gamma                                       \n",
       "900  1.2     0.001                        -4982.341694   \n",
       "     0.8     0.001                        -4977.721671   \n",
       "     1.0     0.001                        -4990.464732   \n",
       "1000 1.2     0.001                        -5120.097183   \n",
       "     1.0     0.001                        -5115.190544   \n",
       "1100 1.2     0.001                        -5229.146626   \n",
       "1000 0.8     0.001                        -5127.047703   \n",
       "1100 1.0     0.001                        -5245.808109   \n",
       "     0.8     0.001                        -5237.740106   \n",
       "\n",
       "                    split5_test_neg_mean_squared_error  ...  split2_train_r2  \\\n",
       "C    epsilon gamma                                      ...                    \n",
       "900  1.2     0.001                        -1650.176392  ...         0.647964   \n",
       "     0.8     0.001                        -1649.855607  ...         0.648286   \n",
       "     1.0     0.001                        -1650.998338  ...         0.648019   \n",
       "1000 1.2     0.001                        -1647.672289  ...         0.647665   \n",
       "     1.0     0.001                        -1646.923264  ...         0.647705   \n",
       "1100 1.2     0.001                        -1648.775322  ...         0.646852   \n",
       "1000 0.8     0.001                        -1646.125883  ...         0.647602   \n",
       "1100 1.0     0.001                        -1650.504441  ...         0.646895   \n",
       "     0.8     0.001                        -1649.078066  ...         0.646880   \n",
       "\n",
       "                    split3_train_r2  split4_train_r2  split5_train_r2  \\\n",
       "C    epsilon gamma                                                      \n",
       "900  1.2     0.001         0.641489         0.682541         0.653149   \n",
       "     0.8     0.001         0.641454         0.682409         0.653162   \n",
       "     1.0     0.001         0.641586         0.682616         0.653267   \n",
       "1000 1.2     0.001         0.640706         0.684274         0.652951   \n",
       "     1.0     0.001         0.640633         0.684263         0.653075   \n",
       "1100 1.2     0.001         0.640498         0.684368         0.652321   \n",
       "1000 0.8     0.001         0.640549         0.684390         0.652896   \n",
       "1100 1.0     0.001         0.640323         0.684565         0.652078   \n",
       "     0.8     0.001         0.640355         0.684409         0.652291   \n",
       "\n",
       "                    split6_train_r2  split7_train_r2  split8_train_r2  \\\n",
       "C    epsilon gamma                                                      \n",
       "900  1.2     0.001         0.640280         0.638957         0.738955   \n",
       "     0.8     0.001         0.640262         0.638634         0.738796   \n",
       "     1.0     0.001         0.640152         0.638724         0.738834   \n",
       "1000 1.2     0.001         0.639319         0.638269         0.738301   \n",
       "     1.0     0.001         0.639015         0.638126         0.738134   \n",
       "1100 1.2     0.001         0.638314         0.638066         0.738539   \n",
       "1000 0.8     0.001         0.638715         0.637991         0.737987   \n",
       "1100 1.0     0.001         0.638126         0.637562         0.738595   \n",
       "     0.8     0.001         0.637847         0.637343         0.738465   \n",
       "\n",
       "                    split9_train_r2  mean_train_r2  std_train_r2  \n",
       "C    epsilon gamma                                                \n",
       "900  1.2     0.001         0.637350       0.655799      0.030616  \n",
       "     0.8     0.001         0.636870       0.655705      0.030610  \n",
       "     1.0     0.001         0.636904       0.655746      0.030629  \n",
       "1000 1.2     0.001         0.636167       0.655440      0.030835  \n",
       "     1.0     0.001         0.636149       0.655314      0.030856  \n",
       "1100 1.2     0.001         0.635694       0.654986      0.031116  \n",
       "1000 0.8     0.001         0.636232       0.655247      0.030847  \n",
       "1100 1.0     0.001         0.635486       0.654869      0.031215  \n",
       "     0.8     0.001         0.635451       0.654791      0.031204  \n",
       "\n",
       "[9 rows x 54 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>split0_test_neg_mean_squared_error</th>\n      <th>split1_test_neg_mean_squared_error</th>\n      <th>split2_test_neg_mean_squared_error</th>\n      <th>split3_test_neg_mean_squared_error</th>\n      <th>split4_test_neg_mean_squared_error</th>\n      <th>split5_test_neg_mean_squared_error</th>\n      <th>...</th>\n      <th>split2_train_r2</th>\n      <th>split3_train_r2</th>\n      <th>split4_train_r2</th>\n      <th>split5_train_r2</th>\n      <th>split6_train_r2</th>\n      <th>split7_train_r2</th>\n      <th>split8_train_r2</th>\n      <th>split9_train_r2</th>\n      <th>mean_train_r2</th>\n      <th>std_train_r2</th>\n    </tr>\n    <tr>\n      <th>C</th>\n      <th>epsilon</th>\n      <th>gamma</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">900</th>\n      <th>1.2</th>\n      <th>0.001</th>\n      <td>0.494813</td>\n      <td>0.033647</td>\n      <td>0.054565</td>\n      <td>0.019347</td>\n      <td>-1379.713343</td>\n      <td>-1661.900299</td>\n      <td>-1272.622116</td>\n      <td>-2019.141156</td>\n      <td>-4982.341694</td>\n      <td>-1650.176392</td>\n      <td>...</td>\n      <td>0.647964</td>\n      <td>0.641489</td>\n      <td>0.682541</td>\n      <td>0.653149</td>\n      <td>0.640280</td>\n      <td>0.638957</td>\n      <td>0.738955</td>\n      <td>0.637350</td>\n      <td>0.655799</td>\n      <td>0.030616</td>\n    </tr>\n    <tr>\n      <th>0.8</th>\n      <th>0.001</th>\n      <td>0.502707</td>\n      <td>0.045648</td>\n      <td>0.044878</td>\n      <td>0.008966</td>\n      <td>-1379.725193</td>\n      <td>-1659.945396</td>\n      <td>-1271.592488</td>\n      <td>-2018.294323</td>\n      <td>-4977.721671</td>\n      <td>-1649.855607</td>\n      <td>...</td>\n      <td>0.648286</td>\n      <td>0.641454</td>\n      <td>0.682409</td>\n      <td>0.653162</td>\n      <td>0.640262</td>\n      <td>0.638634</td>\n      <td>0.738796</td>\n      <td>0.636870</td>\n      <td>0.655705</td>\n      <td>0.030610</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <th>0.001</th>\n      <td>0.514203</td>\n      <td>0.059108</td>\n      <td>0.052475</td>\n      <td>0.013371</td>\n      <td>-1380.099748</td>\n      <td>-1659.799173</td>\n      <td>-1272.156979</td>\n      <td>-2014.959455</td>\n      <td>-4990.464732</td>\n      <td>-1650.998338</td>\n      <td>...</td>\n      <td>0.648019</td>\n      <td>0.641586</td>\n      <td>0.682616</td>\n      <td>0.653267</td>\n      <td>0.640152</td>\n      <td>0.638724</td>\n      <td>0.738834</td>\n      <td>0.636904</td>\n      <td>0.655746</td>\n      <td>0.030629</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1000</th>\n      <th>1.2</th>\n      <th>0.001</th>\n      <td>0.503312</td>\n      <td>0.044865</td>\n      <td>0.050578</td>\n      <td>0.021049</td>\n      <td>-1375.678290</td>\n      <td>-1637.074825</td>\n      <td>-1269.449124</td>\n      <td>-2018.776845</td>\n      <td>-5120.097183</td>\n      <td>-1647.672289</td>\n      <td>...</td>\n      <td>0.647665</td>\n      <td>0.640706</td>\n      <td>0.684274</td>\n      <td>0.652951</td>\n      <td>0.639319</td>\n      <td>0.638269</td>\n      <td>0.738301</td>\n      <td>0.636167</td>\n      <td>0.655440</td>\n      <td>0.030835</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <th>0.001</th>\n      <td>0.513101</td>\n      <td>0.057145</td>\n      <td>0.049271</td>\n      <td>0.010598</td>\n      <td>-1377.194540</td>\n      <td>-1639.815569</td>\n      <td>-1269.418890</td>\n      <td>-2016.211512</td>\n      <td>-5115.190544</td>\n      <td>-1646.923264</td>\n      <td>...</td>\n      <td>0.647705</td>\n      <td>0.640633</td>\n      <td>0.684263</td>\n      <td>0.653075</td>\n      <td>0.639015</td>\n      <td>0.638126</td>\n      <td>0.738134</td>\n      <td>0.636149</td>\n      <td>0.655314</td>\n      <td>0.030856</td>\n    </tr>\n    <tr>\n      <th>1100</th>\n      <th>1.2</th>\n      <th>0.001</th>\n      <td>0.523688</td>\n      <td>0.055016</td>\n      <td>0.058477</td>\n      <td>0.021942</td>\n      <td>-1372.068257</td>\n      <td>-1628.848020</td>\n      <td>-1267.648886</td>\n      <td>-2014.375844</td>\n      <td>-5229.146626</td>\n      <td>-1648.775322</td>\n      <td>...</td>\n      <td>0.646852</td>\n      <td>0.640498</td>\n      <td>0.684368</td>\n      <td>0.652321</td>\n      <td>0.638314</td>\n      <td>0.638066</td>\n      <td>0.738539</td>\n      <td>0.635694</td>\n      <td>0.654986</td>\n      <td>0.031116</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <th>0.8</th>\n      <th>0.001</th>\n      <td>0.528805</td>\n      <td>0.049323</td>\n      <td>0.046268</td>\n      <td>0.008795</td>\n      <td>-1374.876997</td>\n      <td>-1639.871308</td>\n      <td>-1271.208021</td>\n      <td>-2019.171843</td>\n      <td>-5127.047703</td>\n      <td>-1646.125883</td>\n      <td>...</td>\n      <td>0.647602</td>\n      <td>0.640549</td>\n      <td>0.684390</td>\n      <td>0.652896</td>\n      <td>0.638715</td>\n      <td>0.637991</td>\n      <td>0.737987</td>\n      <td>0.636232</td>\n      <td>0.655247</td>\n      <td>0.030847</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1100</th>\n      <th>1.0</th>\n      <th>0.001</th>\n      <td>0.479917</td>\n      <td>0.020635</td>\n      <td>0.041684</td>\n      <td>0.003527</td>\n      <td>-1370.285281</td>\n      <td>-1633.166410</td>\n      <td>-1267.301867</td>\n      <td>-2011.537258</td>\n      <td>-5245.808109</td>\n      <td>-1650.504441</td>\n      <td>...</td>\n      <td>0.646895</td>\n      <td>0.640323</td>\n      <td>0.684565</td>\n      <td>0.652078</td>\n      <td>0.638126</td>\n      <td>0.637562</td>\n      <td>0.738595</td>\n      <td>0.635486</td>\n      <td>0.654869</td>\n      <td>0.031215</td>\n    </tr>\n    <tr>\n      <th>0.8</th>\n      <th>0.001</th>\n      <td>0.487814</td>\n      <td>0.039728</td>\n      <td>0.058160</td>\n      <td>0.020757</td>\n      <td>-1371.535973</td>\n      <td>-1636.899866</td>\n      <td>-1266.741891</td>\n      <td>-2015.871834</td>\n      <td>-5237.740106</td>\n      <td>-1649.078066</td>\n      <td>...</td>\n      <td>0.646880</td>\n      <td>0.640355</td>\n      <td>0.684409</td>\n      <td>0.652291</td>\n      <td>0.637847</td>\n      <td>0.637343</td>\n      <td>0.738465</td>\n      <td>0.635451</td>\n      <td>0.654791</td>\n      <td>0.031204</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows × 54 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "gssigmoid.results"
   ]
  },
  {
   "source": [
    "# Grid Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-29-e72b9caf95c8>, line 5)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-e72b9caf95c8>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    param,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "modelfinal = SVR(max_iter= 10000)\n",
    "kernel = ['rbf','poly']\n",
    "degree = [7,9,11]\n",
    "gamma = ['auto']\n",
    "C =  np.logspace(-5, 5, 5)\n",
    "epsilon =  np.logspace(-5, 5, 5)\n",
    "paramr = {'C':C, 'gamma':gamma, 'degree':degree, 'epsilon':epsilon, 'kernel'=kernel}\n",
    "\n",
    "gsrp = GridSearchCV(modelfinal,paramr,cv=10)\n",
    "\n",
    "gsrp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}