{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data import train, validation\n",
    "from data import X, y, numerical, categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      attribute2  clickVolume  avgOriginalUnitPrice  avgFinalUnitPrice  \\\n",
       "1404    4.850075     3.082306              4.281904           3.791205   \n",
       "2184    2.910045     0.094506              1.709888           1.637009   \n",
       "796     4.850075     0.217541              0.994800           1.103595   \n",
       "25      3.880060     0.327738              1.566200           1.306937   \n",
       "1745    4.850075     0.389791              2.506703           2.351882   \n",
       "\n",
       "      ma14SalesVolume   meanAge    gender  meanEducation  maritalStatus  \\\n",
       "1404         6.480146  7.813408  1.380382      11.580054       2.201123   \n",
       "2184         0.059201  7.600842  0.000000      10.896544       1.410243   \n",
       "796          0.193577  7.016162  0.849466      11.865126       0.987170   \n",
       "25           0.509315  6.876952  0.000000      10.805739       1.645284   \n",
       "1745         0.265934  8.667627  1.162427      11.653248       3.117380   \n",
       "\n",
       "          plus  ...  brandID_33  weekday_2  weekday_3  weekday_4  weekday_5  \\\n",
       "1404  1.650476  ...         0.0        0.0        0.0        0.0        1.0   \n",
       "2184  1.856786  ...         0.0        0.0        0.0        0.0        0.0   \n",
       "796   0.866500  ...         0.0        0.0        0.0        0.0        0.0   \n",
       "25    1.624688  ...         0.0        0.0        1.0        0.0        0.0   \n",
       "1745  1.476989  ...         0.0        0.0        1.0        0.0        0.0   \n",
       "\n",
       "      weekday_6  weekday_7  attribute1_2  attribute1_3  attribute1_4  \n",
       "1404        0.0        0.0           0.0           1.0           0.0  \n",
       "2184        1.0        0.0           0.0           1.0           0.0  \n",
       "796         1.0        0.0           0.0           1.0           0.0  \n",
       "25          0.0        0.0           0.0           1.0           0.0  \n",
       "1745        0.0        0.0           0.0           1.0           0.0  \n",
       "\n",
       "[5 rows x 124 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attribute2</th>\n      <th>clickVolume</th>\n      <th>avgOriginalUnitPrice</th>\n      <th>avgFinalUnitPrice</th>\n      <th>ma14SalesVolume</th>\n      <th>meanAge</th>\n      <th>gender</th>\n      <th>meanEducation</th>\n      <th>maritalStatus</th>\n      <th>plus</th>\n      <th>...</th>\n      <th>brandID_33</th>\n      <th>weekday_2</th>\n      <th>weekday_3</th>\n      <th>weekday_4</th>\n      <th>weekday_5</th>\n      <th>weekday_6</th>\n      <th>weekday_7</th>\n      <th>attribute1_2</th>\n      <th>attribute1_3</th>\n      <th>attribute1_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1404</th>\n      <td>4.850075</td>\n      <td>3.082306</td>\n      <td>4.281904</td>\n      <td>3.791205</td>\n      <td>6.480146</td>\n      <td>7.813408</td>\n      <td>1.380382</td>\n      <td>11.580054</td>\n      <td>2.201123</td>\n      <td>1.650476</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2184</th>\n      <td>2.910045</td>\n      <td>0.094506</td>\n      <td>1.709888</td>\n      <td>1.637009</td>\n      <td>0.059201</td>\n      <td>7.600842</td>\n      <td>0.000000</td>\n      <td>10.896544</td>\n      <td>1.410243</td>\n      <td>1.856786</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>4.850075</td>\n      <td>0.217541</td>\n      <td>0.994800</td>\n      <td>1.103595</td>\n      <td>0.193577</td>\n      <td>7.016162</td>\n      <td>0.849466</td>\n      <td>11.865126</td>\n      <td>0.987170</td>\n      <td>0.866500</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3.880060</td>\n      <td>0.327738</td>\n      <td>1.566200</td>\n      <td>1.306937</td>\n      <td>0.509315</td>\n      <td>6.876952</td>\n      <td>0.000000</td>\n      <td>10.805739</td>\n      <td>1.645284</td>\n      <td>1.624688</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1745</th>\n      <td>4.850075</td>\n      <td>0.389791</td>\n      <td>2.506703</td>\n      <td>2.351882</td>\n      <td>0.265934</td>\n      <td>8.667627</td>\n      <td>1.162427</td>\n      <td>11.653248</td>\n      <td>3.117380</td>\n      <td>1.476989</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 124 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "source": [
    "# Sklearn regression pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Stage 1: Feature Engineering + Feature Selection\n",
    "We first use a grid search to consider:\n",
    "- Power transformations on the response variable\n",
    "- Adding polynomial terms for predictors \n",
    "- Adding interaction terms for predictors\n",
    "Within each parameter combination, models additionally undergo a backwards variable selection procedure using validation MSE as a metric. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Setup for grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = dict()\n",
    "param_grid = dict()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Feature engineering (Preprocessing)\n",
    "\n",
    "We create a preprocessing pipeline (`preprocessor`) to later embed into the overall model pipeline. The preprocessor is kept seperate so that it can also be transferred to other models.\n",
    "\n",
    "We consider optionally adding polynomial and interaction terms of up to degree 3 (`PolynomialFeatures`), one of the feature selection steps outlined above, as well as a power transformation (`PowerTransformer`) to normalize the response."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipeline['preprocessing'] = Pipeline([\n",
    "    ('categorical', 'passthrough'),\n",
    "    ('numerical', ColumnTransformer([\n",
    "        ('poly', PolynomialFeatures(), numerical),\n",
    "        ('drop', VarianceThreshold(), numerical),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "param_grid['preprocessing'] = {\n",
    "    'numerical__poly': [\n",
    "        PolynomialFeatures(degree=3, include_bias=False),\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        'passthrough'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "source": [
    "### Feature selection\n",
    "\n",
    "1. RFE (Recursive feature Elimination) removes variables with low coefficients. \n",
    "  - O\\[k\\] at each step, k is number of cross validation folds. \n",
    "  - May have trouble finding global optimum. \n",
    "  - *Guaranteed* local optimum.\n",
    "\n",
    "2. Sequential feature selection removes variables by test MSE.\n",
    "  - O\\[kn\\] at each step, k is number of cross validation folds, n is number of features.\n",
    "  - Intuitively feels more likely to find global optimum.\n",
    "  - However, cannot even guarantee a local optimum without some manual searching.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV, SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline['dim_reduction'] = Pipeline([\n",
    "    ('method', 'passthrough'),\n",
    "])\n",
    "\n",
    "param_grid['dim_reduction'] = {\n",
    "    'method': [\n",
    "        SequentialFeatureSelector(\n",
    "            estimator = LinearRegression(),\n",
    "            direction = 'backward',\n",
    "            scoring = 'neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "        ),\n",
    "        RFECV(\n",
    "            estimator = LinearRegression(),\n",
    "            scoring = 'neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "        ),\n",
    "        'passthrough',\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "source": [
    "### Standard OLS model\n",
    "\n",
    "Having previously noted the non-normal distribution of the response, we consider a standard OLS model with an optional power transformation to normalize the response. \n",
    "\n",
    "Regularization will be considered in the next stage once optimal input parameters have been found."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pipeline['model_fitting'] = Pipeline([\n",
    "    ('method', 'passthrough'), # Set in param grid\n",
    "])\n",
    "\n",
    "param_grid['model_fitting'] = {\n",
    "    'method': [\n",
    "        TransformedTargetRegressor(\n",
    "            regressor = LinearRegression(),\n",
    "            transformer = PowerTransformer(),\n",
    "        ),\n",
    "        LinearRegression(),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "source": [
    "### Final Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator = Pipeline([\n",
    "        (name, pipe) \n",
    "        for name, pipe in pipeline.items()\n",
    "    ]),\n",
    "    param_grid = {\n",
    "        f'{name}__{param}': value \n",
    "        for name, subgrid in param_grid.items()\n",
    "        for param, value in subgrid.items()\n",
    "    },\n",
    "    scoring = ['r2', 'neg_mean_squared_error'],\n",
    "    refit = 'neg_mean_squared_error',\n",
    "    return_train_score = True,\n",
    "    verbose = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================================================================\nPipeline Structure\n--------------------------------------------------------------------------------\nPipeline(steps=[('preprocessing',\n                 Pipeline(steps=[('categorical', 'passthrough'),\n                                 ('numerical',\n                                  ColumnTransformer(transformers=[('poly',\n                                                                   PolynomialFeatures(),\n                                                                   ['attribute2',\n                                                                    'clickVolume',\n                                                                    'avgOriginalUnitPrice',\n                                                                    'avgFinalUnitPrice',\n                                                                    'ma14SalesVolume',\n                                                                    'meanAge',\n                                                                    'gender',\n                                                                    'meanEducation',\n                                                                    'maritalStatus',\n                                                                    'plus',\n                                                                    'meanPurchasePower',\n                                                                    'meanUserLevel',\n                                                                    'meanCityLevel...\n                                                                   VarianceThreshold(),\n                                                                   ['attribute2',\n                                                                    'clickVolume',\n                                                                    'avgOriginalUnitPrice',\n                                                                    'avgFinalUnitPrice',\n                                                                    'ma14SalesVolume',\n                                                                    'meanAge',\n                                                                    'gender',\n                                                                    'meanEducation',\n                                                                    'maritalStatus',\n                                                                    'plus',\n                                                                    'meanPurchasePower',\n                                                                    'meanUserLevel',\n                                                                    'meanCityLevel'])]))])),\n                ('dim_reduction', Pipeline(steps=[('method', 'passthrough')])),\n                ('model_fitting', Pipeline(steps=[('method', 'passthrough')]))])\n"
     ]
    }
   ],
   "source": [
    "print(80*'=')\n",
    "print('Pipeline Structure')\n",
    "print(80*'-')\n",
    "print(search.estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "================================================================================\nParameter Space\n--------------------------------------------------------------------------------\npreprocessing__numerical__poly\n- PolynomialFeatures(degree=3, include_bias=False)\n- PolynomialFeatures(include_bias=False)\n- passthrough\n\ndim_reduction__method\n- RFECV(estimator=LinearRegression(), n_jobs=-1, scoring='neg_mean_squared_error')\n- SequentialFeatureSelector(direction='backward', estimator=LinearRegression(),\n                          n_jobs=-1, scoring='neg_mean_squared_error')\n- passthrough\n\nmodel_fitting__method\n- TransformedTargetRegressor(regressor=LinearRegression(),\n                           transformer=PowerTransformer())\n- LinearRegression()\n\n"
     ]
    }
   ],
   "source": [
    "print(80*'=')\n",
    "print('Parameter Space')\n",
    "print(80*'-')\n",
    "for param, values in search.param_grid.items():\n",
    "    print(param)\n",
    "    for value in values:\n",
    "        print('-', value)\n",
    "    print()"
   ]
  },
  {
   "source": [
    "### Grid Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pickle \n",
    "\n",
    "search.fit(train[X], train[y])\n",
    "\n",
    "# Save results\n",
    "with open('linreg.p', 'wb') as f:\n",
    "    pickle.dump(search, f)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "source": [
    "### Stage 2: Model regularization\n",
    "Model inputs are now fixed and we consider usign a mix of L1 and L2 regularization (ElasticNet) to finely control the strength of the penalty for large coefficients. The best set of regularization parameters are obtained through a grid search."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}